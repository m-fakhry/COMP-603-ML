# Lecture 1

## Foundations 

- Machine Learning vs Algorithm
- Regression vs Classification 

## Linear Regression

- What is linear regression 
- A mapping function from $X$ to $y$ with parameters $\theta$ to learn. 
- How to learn parameters 
- min and max saddle points, derivative equals to zero. 
- Differentiable, first derivative, Jacobian and Hessian. 
- Loss functions: error, absolute error, mean squared error
- loss in both element-wise notation and matrix notation  $(X\theta-y)^T(X\theta-y)$
- minimization problem $min_{\theta} \; l(X\theta,y)$
- closed-form solution 
